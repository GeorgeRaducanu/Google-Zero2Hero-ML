{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Starter Code - Classification on Unlabeled and Mislabeled Images","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-04T10:13:27.285031Z","iopub.execute_input":"2023-07-04T10:13:27.285725Z","iopub.status.idle":"2023-07-04T10:13:27.586428Z","shell.execute_reply.started":"2023-07-04T10:13:27.285687Z","shell.execute_reply":"2023-07-04T10:13:27.585492Z"}}},{"cell_type":"markdown","source":"<h4> Import Libraries </h4>","metadata":{}},{"cell_type":"code","source":"import os\nimport sys\n\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom tqdm import tqdm\n\n# Pytorch imports\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset, DataLoader","metadata":{"execution":{"iopub.status.busy":"2023-07-13T15:33:05.030544Z","iopub.execute_input":"2023-07-13T15:33:05.031156Z","iopub.status.idle":"2023-07-13T15:33:05.041692Z","shell.execute_reply.started":"2023-07-13T15:33:05.031108Z","shell.execute_reply":"2023-07-13T15:33:05.040602Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"markdown","source":"<h4> Training Configuration </h4>\nYou should experiment with different hyperparameters","metadata":{}},{"cell_type":"code","source":"CONFIG = {\"seed\": 114,\n          \"epochs\": 500,\n          \"img_size\": 64,\n          \"num_classes\": 30,\n          \"train_batch_size\": 256,\n          \"val_batch_size\": 256,\n          \"learning_rate\": 0.0008,\n          \"num_workers\": 2,\n          \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n          # StepLR Scheduler hyperparameters\n          \"step_size\": 10,\n          \"gamma\": 0.95\n          }","metadata":{"execution":{"iopub.status.busy":"2023-07-13T15:33:05.046337Z","iopub.execute_input":"2023-07-13T15:33:05.046878Z","iopub.status.idle":"2023-07-13T15:33:05.060031Z","shell.execute_reply.started":"2023-07-13T15:33:05.046838Z","shell.execute_reply":"2023-07-13T15:33:05.059108Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"markdown","source":"<h4> Set seed for reproducibility </h4>","metadata":{}},{"cell_type":"code","source":"torch.manual_seed(CONFIG[\"seed\"])\ntorch.cuda.manual_seed(CONFIG[\"seed\"])","metadata":{"execution":{"iopub.status.busy":"2023-07-13T15:33:05.061790Z","iopub.execute_input":"2023-07-13T15:33:05.062433Z","iopub.status.idle":"2023-07-13T15:33:05.073095Z","shell.execute_reply.started":"2023-07-13T15:33:05.062395Z","shell.execute_reply":"2023-07-13T15:33:05.071967Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"markdown","source":"<h4> Data Directories </h4>","metadata":{}},{"cell_type":"code","source":"ROOT_DIR = '/kaggle/input/classification-on-unlabeled-and-mislabeled-images/'\nTRAIN_LABELED_DIR = os.path.join(ROOT_DIR, 'train/train/labeled_images/')\nTRAIN_UNLABELED_DIR = os.path.join(ROOT_DIR, 'train/train/unlabeled_images/')\nTEST_DIR = os.path.join(ROOT_DIR, 'test/test/images/')\nSAVE_PATH = \"best_model.pth\"","metadata":{"execution":{"iopub.status.busy":"2023-07-13T15:33:05.076298Z","iopub.execute_input":"2023-07-13T15:33:05.076767Z","iopub.status.idle":"2023-07-13T15:33:05.085153Z","shell.execute_reply.started":"2023-07-13T15:33:05.076731Z","shell.execute_reply":"2023-07-13T15:33:05.083951Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"markdown","source":"<h4> Read the CSV </h4>","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(os.path.join(ROOT_DIR, 'train_annotations.csv'))\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-07-13T15:33:05.087557Z","iopub.execute_input":"2023-07-13T15:33:05.088470Z","iopub.status.idle":"2023-07-13T15:33:05.112430Z","shell.execute_reply.started":"2023-07-13T15:33:05.088432Z","shell.execute_reply":"2023-07-13T15:33:05.111444Z"},"trusted":true},"execution_count":92,"outputs":[{"execution_count":92,"output_type":"execute_result","data":{"text/plain":"    image_name  class_name\n0  000000.JPEG      250605\n1  000001.JPEG      516810\n2  000002.JPEG      289648\n3  000003.JPEG      688319\n4  000004.JPEG      964607","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>class_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000000.JPEG</td>\n      <td>250605</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000001.JPEG</td>\n      <td>516810</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000002.JPEG</td>\n      <td>289648</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>000003.JPEG</td>\n      <td>688319</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>000004.JPEG</td>\n      <td>964607</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"<h4> Create mapping for class_name </h4>","metadata":{}},{"cell_type":"code","source":"class_names = df.class_name.unique()\nclass_to_index_mapping = {}\nindex_to_class_mapping = {}\nfor i in range(CONFIG['num_classes']):\n    class_to_index_mapping[class_names[i]] = i\n    index_to_class_mapping[i] = class_names[i]\nclass_to_index_mapping","metadata":{"execution":{"iopub.status.busy":"2023-07-13T15:33:05.115011Z","iopub.execute_input":"2023-07-13T15:33:05.115316Z","iopub.status.idle":"2023-07-13T15:33:05.127678Z","shell.execute_reply.started":"2023-07-13T15:33:05.115290Z","shell.execute_reply":"2023-07-13T15:33:05.126369Z"},"trusted":true},"execution_count":93,"outputs":[{"execution_count":93,"output_type":"execute_result","data":{"text/plain":"{250605: 0,\n 516810: 1,\n 289648: 2,\n 688319: 3,\n 964607: 4,\n 431115: 5,\n 517908: 6,\n 44558: 7,\n 665003: 8,\n 500192: 9,\n 477273: 10,\n 335856: 11,\n 158226: 12,\n 914948: 13,\n 690093: 14,\n 759848: 15,\n 28368: 16,\n 612747: 17,\n 812491: 18,\n 589958: 19,\n 436479: 20,\n 358316: 21,\n 339246: 22,\n 537498: 23,\n 146725: 24,\n 896857: 25,\n 877556: 26,\n 56639: 27,\n 648396: 28,\n 821885: 29}"},"metadata":{}}]},{"cell_type":"markdown","source":"<h4> Dataset Class </h4>","metadata":{}},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, csv_path, data_dir, transform, dataset_type='train'):\n        self.transform = transform\n        df = pd.read_csv(csv_path)\n        self.data_dir = data_dir\n        \n        # Split training set into train and validation\n        train_data=df.sample(frac=0.8,random_state=CONFIG['seed'])\n        if dataset_type == 'train':\n            self.data = train_data\n        elif dataset_type == 'val':\n            self.data=df.drop(train_data.index)\n\n        # For submission use full training set\n        elif dataset_type == 'full-train':\n                self.data = df\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        row = self.data.iloc[idx]\n\n        img_path = os.path.join(self.data_dir, row['image_name'])\n        img_label = class_to_index_mapping[row.class_name]\n\n        img = Image.open(img_path).convert(\"RGB\")\n\n        if self.transform:\n            img = self.transform(img)        \n            \n        output = {'img': img, 'label': img_label}\n\n        return output","metadata":{"execution":{"iopub.status.busy":"2023-07-13T15:33:05.132304Z","iopub.execute_input":"2023-07-13T15:33:05.132666Z","iopub.status.idle":"2023-07-13T15:33:05.144321Z","shell.execute_reply.started":"2023-07-13T15:33:05.132629Z","shell.execute_reply":"2023-07-13T15:33:05.143231Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"code","source":"# Dataset for loading unlabeled set and test set\n\nclass UnlabeledDataset(Dataset):\n    def __init__(self, data_dir, transform):\n        self.transform = transform\n        self.data_dir = data_dir\n        self.img_names = [filename for filename in sorted(os.listdir(self.data_dir))]\n\n    def __len__(self):\n        return len(self.img_names)\n\n    def __getitem__(self, idx):\n        img_path = os.path.join(self.data_dir, self.img_names[idx])\n\n        img = Image.open(img_path).convert(\"RGB\")\n\n        if self.transform:\n            img = self.transform(img)        \n            \n        output = {'img': img, 'img_name': self.img_names[idx]}\n\n        return output","metadata":{"execution":{"iopub.status.busy":"2023-07-13T15:33:05.146703Z","iopub.execute_input":"2023-07-13T15:33:05.147780Z","iopub.status.idle":"2023-07-13T15:33:05.162000Z","shell.execute_reply.started":"2023-07-13T15:33:05.147746Z","shell.execute_reply":"2023-07-13T15:33:05.160900Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"markdown","source":"<h4> Augmentations </h4>\nYou should experiment with adding/removing transforms","metadata":{}},{"cell_type":"code","source":"train_transforms = transforms.Compose([\n    transforms.Resize(CONFIG['img_size']),\n    transforms.RandomResizedCrop(CONFIG['img_size']),\n    transforms.RandomRotation(degrees=10),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomVerticalFlip(p=0.5),\n    transforms.ColorJitter(brightness=0.25, contrast=0.25, saturation=0.25),\n    transforms.RandomGrayscale(p=0.1),\n    transforms.RandomCrop(CONFIG['img_size'], padding=4),\n    transforms.RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(0.9, 1.1), shear=15),\n    transforms.RandomPerspective(distortion_scale=0.2, p=0.2),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229,0.224,0.225]),\n])\n\ntest_transforms = transforms.Compose([\n    transforms.Resize(CONFIG['img_size']),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229,0.224,0.225]),\n])","metadata":{"execution":{"iopub.status.busy":"2023-07-13T15:33:05.163630Z","iopub.execute_input":"2023-07-13T15:33:05.164147Z","iopub.status.idle":"2023-07-13T15:33:05.177375Z","shell.execute_reply.started":"2023-07-13T15:33:05.164053Z","shell.execute_reply":"2023-07-13T15:33:05.176454Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"markdown","source":"<h4> Prepare Data loaders </h4>","metadata":{}},{"cell_type":"code","source":"def prepare_loaders():\n    train_set = CustomDataset(\n        csv_path = os.path.join(ROOT_DIR, 'train_annotations.csv'),\n        data_dir = TRAIN_LABELED_DIR,\n        transform = train_transforms,\n        dataset_type ='train'\n    )\n    \n    train_loader = DataLoader(\n        train_set,\n        batch_size = CONFIG['train_batch_size'], \n        shuffle = True,\n        num_workers = CONFIG['num_workers'], \n        pin_memory = True\n    )\n    \n    val_set = CustomDataset(\n        csv_path = os.path.join(ROOT_DIR, 'train_annotations.csv'),\n        data_dir = TRAIN_LABELED_DIR,\n        transform = test_transforms,\n        dataset_type ='val'\n    )\n    \n    val_loader = DataLoader(\n        val_set,\n        batch_size = CONFIG['val_batch_size'], \n        shuffle = False,\n        num_workers = CONFIG['num_workers'], \n        pin_memory = True\n    )\n\n    return train_loader, val_loader\n    ","metadata":{"execution":{"iopub.status.busy":"2023-07-13T15:33:05.181389Z","iopub.execute_input":"2023-07-13T15:33:05.182309Z","iopub.status.idle":"2023-07-13T15:33:05.195303Z","shell.execute_reply.started":"2023-07-13T15:33:05.182275Z","shell.execute_reply":"2023-07-13T15:33:05.194272Z"},"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"markdown","source":"<h4> Create model </h4>\nYou should experiment with different models by modifying existing ones or constructing new models from scratch","metadata":{}},{"cell_type":"code","source":"from torchvision.models import densenet201\n\nclass ResnetModel(nn.Module):\n    def __init__(self, num_classes):\n        super(ResnetModel, self).__init__()\n        self.backbone = densenet201()\n        \n        # Change the classification head to have num_classes output neurons\n        in_features = self.backbone.classifier.in_features\n        self.backbone.classifier = nn.Linear(in_features=in_features, out_features=num_classes, bias=True)\n    \n    def forward(self, x):\n        x = self.backbone(x)\n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2023-07-13T15:33:05.198933Z","iopub.execute_input":"2023-07-13T15:33:05.199239Z","iopub.status.idle":"2023-07-13T15:33:05.208490Z","shell.execute_reply.started":"2023-07-13T15:33:05.199215Z","shell.execute_reply":"2023-07-13T15:33:05.207599Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"code","source":"model = ResnetModel(num_classes=CONFIG['num_classes'])\nmodel.to(CONFIG['device'])","metadata":{"execution":{"iopub.status.busy":"2023-07-13T15:33:05.211375Z","iopub.execute_input":"2023-07-13T15:33:05.213768Z","iopub.status.idle":"2023-07-13T15:33:05.713364Z","shell.execute_reply.started":"2023-07-13T15:33:05.213740Z","shell.execute_reply":"2023-07-13T15:33:05.712497Z"},"trusted":true},"execution_count":99,"outputs":[{"execution_count":99,"output_type":"execute_result","data":{"text/plain":"ResnetModel(\n  (backbone): DenseNet(\n    (features): Sequential(\n      (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n      (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu0): ReLU(inplace=True)\n      (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n      (denseblock1): _DenseBlock(\n        (denselayer1): _DenseLayer(\n          (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer2): _DenseLayer(\n          (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer3): _DenseLayer(\n          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer4): _DenseLayer(\n          (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer5): _DenseLayer(\n          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer6): _DenseLayer(\n          (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n      )\n      (transition1): _Transition(\n        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n      )\n      (denseblock2): _DenseBlock(\n        (denselayer1): _DenseLayer(\n          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer2): _DenseLayer(\n          (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer3): _DenseLayer(\n          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer4): _DenseLayer(\n          (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer5): _DenseLayer(\n          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer6): _DenseLayer(\n          (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer7): _DenseLayer(\n          (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer8): _DenseLayer(\n          (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer9): _DenseLayer(\n          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer10): _DenseLayer(\n          (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer11): _DenseLayer(\n          (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer12): _DenseLayer(\n          (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n      )\n      (transition2): _Transition(\n        (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n      )\n      (denseblock3): _DenseBlock(\n        (denselayer1): _DenseLayer(\n          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer2): _DenseLayer(\n          (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer3): _DenseLayer(\n          (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer4): _DenseLayer(\n          (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer5): _DenseLayer(\n          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer6): _DenseLayer(\n          (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer7): _DenseLayer(\n          (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer8): _DenseLayer(\n          (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer9): _DenseLayer(\n          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer10): _DenseLayer(\n          (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer11): _DenseLayer(\n          (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer12): _DenseLayer(\n          (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer13): _DenseLayer(\n          (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer14): _DenseLayer(\n          (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer15): _DenseLayer(\n          (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer16): _DenseLayer(\n          (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer17): _DenseLayer(\n          (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer18): _DenseLayer(\n          (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer19): _DenseLayer(\n          (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer20): _DenseLayer(\n          (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer21): _DenseLayer(\n          (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer22): _DenseLayer(\n          (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer23): _DenseLayer(\n          (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer24): _DenseLayer(\n          (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer25): _DenseLayer(\n          (norm1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer26): _DenseLayer(\n          (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer27): _DenseLayer(\n          (norm1): BatchNorm2d(1088, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer28): _DenseLayer(\n          (norm1): BatchNorm2d(1120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(1120, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer29): _DenseLayer(\n          (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(1152, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer30): _DenseLayer(\n          (norm1): BatchNorm2d(1184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(1184, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer31): _DenseLayer(\n          (norm1): BatchNorm2d(1216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(1216, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer32): _DenseLayer(\n          (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(1248, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer33): _DenseLayer(\n          (norm1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(1280, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer34): _DenseLayer(\n          (norm1): BatchNorm2d(1312, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(1312, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer35): _DenseLayer(\n          (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(1344, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer36): _DenseLayer(\n          (norm1): BatchNorm2d(1376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(1376, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer37): _DenseLayer(\n          (norm1): BatchNorm2d(1408, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(1408, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer38): _DenseLayer(\n          (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(1440, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer39): _DenseLayer(\n          (norm1): BatchNorm2d(1472, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(1472, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer40): _DenseLayer(\n          (norm1): BatchNorm2d(1504, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(1504, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer41): _DenseLayer(\n          (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(1536, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer42): _DenseLayer(\n          (norm1): BatchNorm2d(1568, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(1568, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer43): _DenseLayer(\n          (norm1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(1600, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer44): _DenseLayer(\n          (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(1632, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer45): _DenseLayer(\n          (norm1): BatchNorm2d(1664, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(1664, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer46): _DenseLayer(\n          (norm1): BatchNorm2d(1696, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(1696, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer47): _DenseLayer(\n          (norm1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(1728, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer48): _DenseLayer(\n          (norm1): BatchNorm2d(1760, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(1760, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n      )\n      (transition3): _Transition(\n        (norm): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv): Conv2d(1792, 896, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n      )\n      (denseblock4): _DenseBlock(\n        (denselayer1): _DenseLayer(\n          (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer2): _DenseLayer(\n          (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer3): _DenseLayer(\n          (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer4): _DenseLayer(\n          (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer5): _DenseLayer(\n          (norm1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer6): _DenseLayer(\n          (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer7): _DenseLayer(\n          (norm1): BatchNorm2d(1088, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer8): _DenseLayer(\n          (norm1): BatchNorm2d(1120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(1120, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer9): _DenseLayer(\n          (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(1152, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer10): _DenseLayer(\n          (norm1): BatchNorm2d(1184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(1184, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer11): _DenseLayer(\n          (norm1): BatchNorm2d(1216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(1216, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer12): _DenseLayer(\n          (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(1248, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer13): _DenseLayer(\n          (norm1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(1280, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer14): _DenseLayer(\n          (norm1): BatchNorm2d(1312, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(1312, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer15): _DenseLayer(\n          (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(1344, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer16): _DenseLayer(\n          (norm1): BatchNorm2d(1376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(1376, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer17): _DenseLayer(\n          (norm1): BatchNorm2d(1408, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(1408, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer18): _DenseLayer(\n          (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(1440, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer19): _DenseLayer(\n          (norm1): BatchNorm2d(1472, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(1472, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer20): _DenseLayer(\n          (norm1): BatchNorm2d(1504, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(1504, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer21): _DenseLayer(\n          (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(1536, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer22): _DenseLayer(\n          (norm1): BatchNorm2d(1568, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(1568, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer23): _DenseLayer(\n          (norm1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(1600, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer24): _DenseLayer(\n          (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(1632, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer25): _DenseLayer(\n          (norm1): BatchNorm2d(1664, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(1664, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer26): _DenseLayer(\n          (norm1): BatchNorm2d(1696, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(1696, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer27): _DenseLayer(\n          (norm1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(1728, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer28): _DenseLayer(\n          (norm1): BatchNorm2d(1760, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(1760, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer29): _DenseLayer(\n          (norm1): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(1792, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer30): _DenseLayer(\n          (norm1): BatchNorm2d(1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(1824, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer31): _DenseLayer(\n          (norm1): BatchNorm2d(1856, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(1856, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n        (denselayer32): _DenseLayer(\n          (norm1): BatchNorm2d(1888, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu1): ReLU(inplace=True)\n          (conv1): Conv2d(1888, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu2): ReLU(inplace=True)\n          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        )\n      )\n      (norm5): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (classifier): Linear(in_features=1920, out_features=30, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"markdown","source":"<h4> Training Helpers </h4>\nYou are encouraged to experiment with different scheduler types and parameters","metadata":{}},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\n\noptimizer = optim.AdamW(model.parameters(), lr=CONFIG['learning_rate'])\nscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=CONFIG['step_size'], gamma=CONFIG['gamma'])","metadata":{"execution":{"iopub.status.busy":"2023-07-13T15:33:05.714871Z","iopub.execute_input":"2023-07-13T15:33:05.715946Z","iopub.status.idle":"2023-07-13T15:33:05.725922Z","shell.execute_reply.started":"2023-07-13T15:33:05.715909Z","shell.execute_reply":"2023-07-13T15:33:05.725031Z"},"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"markdown","source":"<h4> Training function </h4>","metadata":{}},{"cell_type":"code","source":"def train_epoch(model, dataloader, device, epoch):\n    model.train()\n    \n    total_train_loss = 0.0\n    dataset_size = 0\n    \n    bar = tqdm(enumerate(dataloader), total=len(dataloader), colour='cyan', file=sys.stdout)\n    for step, data in bar:\n        images = data['img'].to(device)\n        labels = data['label'].to(device)\n        \n        batch_size = images.shape[0]\n\n        optimizer.zero_grad()\n        pred = model(images)\n        loss = criterion(pred, labels)\n\n        loss.backward()\n        optimizer.step()\n\n        total_train_loss += (loss.item() * batch_size)\n        dataset_size += batch_size\n        \n        epoch_loss = np.round(total_train_loss / dataset_size, 2)\n        bar.set_postfix(Epoch=epoch, Train_Loss=epoch_loss)\n\n    scheduler.step()\n\n\n    return epoch_loss","metadata":{"execution":{"iopub.status.busy":"2023-07-13T15:33:05.729207Z","iopub.execute_input":"2023-07-13T15:33:05.729549Z","iopub.status.idle":"2023-07-13T15:33:05.739757Z","shell.execute_reply.started":"2023-07-13T15:33:05.729511Z","shell.execute_reply":"2023-07-13T15:33:05.738689Z"},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"markdown","source":"<h4> Validation function </h4>","metadata":{}},{"cell_type":"code","source":"def valid_epoch(model, dataloader, device, epoch):\n    model.eval()\n    \n    total_val_loss = 0.0\n    dataset_size = 0\n    \n    correct = 0\n\n    bar = tqdm(enumerate(dataloader), total=len(dataloader), colour='cyan', file=sys.stdout)\n    for step, data in bar:\n        images = data['img'].to(device)\n        labels = data['label'].to(device)\n        \n        batch_size = images.shape[0]\n\n        pred = model(images)\n        loss = criterion(pred, labels)\n        \n        _, predicted = torch.max(pred, 1)\n        correct += (predicted == labels).sum().item()\n        \n        total_val_loss += (loss.item() * batch_size)\n        dataset_size += batch_size\n        \n        epoch_loss = np.round(total_val_loss / dataset_size, 2)\n    \n        accuracy = np.round(100 * correct / dataset_size, 2)\n\n        bar.set_postfix(Epoch=epoch, Valid_Acc=accuracy, Valid_Loss=epoch_loss)\n\n    return accuracy, epoch_loss","metadata":{"execution":{"iopub.status.busy":"2023-07-13T15:33:05.741275Z","iopub.execute_input":"2023-07-13T15:33:05.741844Z","iopub.status.idle":"2023-07-13T15:33:05.753900Z","shell.execute_reply.started":"2023-07-13T15:33:05.741811Z","shell.execute_reply":"2023-07-13T15:33:05.753024Z"},"trusted":true},"execution_count":102,"outputs":[]},{"cell_type":"markdown","source":"<h4> Build submission file </h4>","metadata":{}},{"cell_type":"code","source":"def build_submission(model, dataloader, device, submission_file):\n    model.eval()\n    \n    all_predictions = []\n    all_image_names = []\n\n    for data in dataloader:\n        images = data['img'].to(device)\n        img_names = data['img_name']\n        pred = model(images)\n        _, predicted = torch.max(pred, 1)\n        \n        predicted = predicted.cpu().numpy().tolist()\n        all_predictions.extend(predicted)\n        all_image_names.extend(img_names)\n    \n    all_predictions = [index_to_class_mapping[prediction] for prediction in all_predictions]\n    data = list(zip(all_image_names, all_predictions))\n    submission_df = pd.DataFrame(data=data, columns=['image_name', 'class_name'])\n    submission_df.to_csv(submission_file, index=False)\n    print(f\"Submission saved to {submission_file}\")","metadata":{"execution":{"iopub.status.busy":"2023-07-13T15:33:05.757886Z","iopub.execute_input":"2023-07-13T15:33:05.758217Z","iopub.status.idle":"2023-07-13T15:33:05.772447Z","shell.execute_reply.started":"2023-07-13T15:33:05.758191Z","shell.execute_reply":"2023-07-13T15:33:05.771609Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"markdown","source":"<h4> Run Training </h4>","metadata":{}},{"cell_type":"code","source":"def run_training(model, device, num_epochs):\n    if torch.cuda.is_available():\n        print(\"[INFO] Using GPU: {}\\n\".format(torch.cuda.get_device_name()))\n    \n    top_accuracy = 0.0\n    \n    train_loader, val_loader = prepare_loaders()\n    for epoch in range(num_epochs):\n        \n        train_loss = train_epoch(model, train_loader, device, epoch)\n        with torch.no_grad():\n            val_accuracy, val_loss = valid_epoch(model, val_loader, device, epoch)\n            if val_accuracy > top_accuracy:\n                print(f\"Validation Accuracy Improved ({top_accuracy} ---> {val_accuracy})\")\n                top_accuracy = val_accuracy\n                torch.save(model.state_dict(), SAVE_PATH)\n                print(\"Model Saved\")\n        print()","metadata":{"execution":{"iopub.status.busy":"2023-07-13T15:33:05.773812Z","iopub.execute_input":"2023-07-13T15:33:05.774249Z","iopub.status.idle":"2023-07-13T15:33:05.786080Z","shell.execute_reply.started":"2023-07-13T15:33:05.774199Z","shell.execute_reply":"2023-07-13T15:33:05.785148Z"},"trusted":true},"execution_count":104,"outputs":[]},{"cell_type":"code","source":"# from torchvision.models import resnet18, resnet34, resnet50, resnet101, resnet152\n# from torchvision.models import densenet121, densenet169, densenet201\n# from torchvision.models import inception_v3\n# from torchvision.models import mobilenet_v2, mobilenet_v3_large, mobilenet_v3_small\n# from torchvision.models import efficientnet_b0, efficientnet_b1, efficientnet_b2, efficientnet_b3\n# from torchvision.models import efficientnet_b4, efficientnet_b5, efficientnet_b6, efficientnet_b7\n\n# class ResnetModel(nn.Module):\n#     def __init__(self, num_classes):\n#         super(ResnetModel, self).__init__()\n#         self.backbone = densenet201()\n        \n#         # Change the classification head to have num_classes output neurons\n#         in_features = self.backbone.classifier.in_features\n#         self.backbone.classifier = nn.Linear(in_features=in_features, out_features=num_classes, bias=True)\n    \n#     def forward(self, x):\n#         x = self.backbone(x)\n#         return x\n","metadata":{"execution":{"iopub.status.busy":"2023-07-13T15:33:05.787848Z","iopub.execute_input":"2023-07-13T15:33:05.788306Z","iopub.status.idle":"2023-07-13T15:33:05.802761Z","shell.execute_reply.started":"2023-07-13T15:33:05.788272Z","shell.execute_reply":"2023-07-13T15:33:05.801883Z"},"trusted":true},"execution_count":105,"outputs":[]},{"cell_type":"code","source":"# model = ResnetModel(num_classes=CONFIG['num_classes'])\n# model.to(CONFIG['device'])\nrun_training(model, CONFIG['device'], CONFIG['epochs'])","metadata":{"execution":{"iopub.status.busy":"2023-07-13T15:33:05.805963Z","iopub.execute_input":"2023-07-13T15:33:05.806338Z","iopub.status.idle":"2023-07-13T15:47:44.823814Z","shell.execute_reply.started":"2023-07-13T15:33:05.806313Z","shell.execute_reply":"2023-07-13T15:47:44.819922Z"},"trusted":true},"execution_count":106,"outputs":[{"name":"stdout","text":"[INFO] Using GPU: Tesla T4\n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:09<00:00,  4.07it/s, Epoch=0, Train_Loss=3.43]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  8.53it/s, Epoch=0, Valid_Acc=9.5, Valid_Loss=4.71]\nValidation Accuracy Improved (0.0 ---> 9.5)\nModel Saved\n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:10<00:00,  3.67it/s, Epoch=1, Train_Loss=3.25]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  9.13it/s, Epoch=1, Valid_Acc=13.5, Valid_Loss=3.1]\nValidation Accuracy Improved (9.5 ---> 13.5)\nModel Saved\n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:09<00:00,  3.91it/s, Epoch=2, Train_Loss=3.15]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  9.35it/s, Epoch=2, Valid_Acc=12.7, Valid_Loss=4.52]\n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:09<00:00,  4.06it/s, Epoch=3, Train_Loss=3.15]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  7.64it/s, Epoch=3, Valid_Acc=14.7, Valid_Loss=3.11]\nValidation Accuracy Improved (13.5 ---> 14.67)\nModel Saved\n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:10<00:00,  3.74it/s, Epoch=4, Train_Loss=3.09]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  8.59it/s, Epoch=4, Valid_Acc=15.3, Valid_Loss=3.45]\nValidation Accuracy Improved (14.67 ---> 15.33)\nModel Saved\n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:09<00:00,  4.00it/s, Epoch=5, Train_Loss=3.09]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  8.64it/s, Epoch=5, Valid_Acc=16.2, Valid_Loss=2.96]\nValidation Accuracy Improved (15.33 ---> 16.17)\nModel Saved\n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:10<00:00,  3.60it/s, Epoch=6, Train_Loss=3.04]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  8.96it/s, Epoch=6, Valid_Acc=16.8, Valid_Loss=2.95]\nValidation Accuracy Improved (16.17 ---> 16.83)\nModel Saved\n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:09<00:00,  3.93it/s, Epoch=7, Train_Loss=3.03]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  9.10it/s, Epoch=7, Valid_Acc=20.2, Valid_Loss=2.92]\nValidation Accuracy Improved (16.83 ---> 20.17)\nModel Saved\n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:09<00:00,  3.89it/s, Epoch=8, Train_Loss=2.97]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  9.13it/s, Epoch=8, Valid_Acc=19.8, Valid_Loss=2.9]\n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:10<00:00,  3.49it/s, Epoch=9, Train_Loss=2.93]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  7.96it/s, Epoch=9, Valid_Acc=19.7, Valid_Loss=3]  \n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:09<00:00,  3.90it/s, Epoch=10, Train_Loss=2.95]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  8.84it/s, Epoch=10, Valid_Acc=19.7, Valid_Loss=2.89]\n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:09<00:00,  3.85it/s, Epoch=11, Train_Loss=2.88]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  8.95it/s, Epoch=11, Valid_Acc=20.8, Valid_Loss=2.9]\nValidation Accuracy Improved (20.17 ---> 20.83)\nModel Saved\n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:10<00:00,  3.59it/s, Epoch=12, Train_Loss=2.92]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  8.50it/s, Epoch=12, Valid_Acc=24, Valid_Loss=2.81] \nValidation Accuracy Improved (20.83 ---> 24.0)\nModel Saved\n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:10<00:00,  3.79it/s, Epoch=13, Train_Loss=2.89]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  6.60it/s, Epoch=13, Valid_Acc=21.5, Valid_Loss=2.92]\n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:11<00:00,  3.29it/s, Epoch=14, Train_Loss=2.86]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  5.87it/s, Epoch=14, Valid_Acc=24.3, Valid_Loss=2.81]\nValidation Accuracy Improved (24.0 ---> 24.33)\nModel Saved\n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:09<00:00,  3.85it/s, Epoch=15, Train_Loss=2.82]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  8.48it/s, Epoch=15, Valid_Acc=21.5, Valid_Loss=3.11]\n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:10<00:00,  3.78it/s, Epoch=16, Train_Loss=2.85]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  8.71it/s, Epoch=16, Valid_Acc=22.2, Valid_Loss=3.26]\n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:10<00:00,  3.55it/s, Epoch=17, Train_Loss=2.8] \n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  8.25it/s, Epoch=17, Valid_Acc=25.7, Valid_Loss=2.72]\nValidation Accuracy Improved (24.33 ---> 25.67)\nModel Saved\n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:09<00:00,  3.82it/s, Epoch=18, Train_Loss=2.77]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  8.86it/s, Epoch=18, Valid_Acc=24.8, Valid_Loss=2.87]\n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:09<00:00,  3.86it/s, Epoch=19, Train_Loss=2.73]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  8.81it/s, Epoch=19, Valid_Acc=27.7, Valid_Loss=2.77]\nValidation Accuracy Improved (25.67 ---> 27.67)\nModel Saved\n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:10<00:00,  3.49it/s, Epoch=20, Train_Loss=2.74]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  8.13it/s, Epoch=20, Valid_Acc=23.8, Valid_Loss=3.42]\n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:10<00:00,  3.79it/s, Epoch=21, Train_Loss=2.73]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  8.89it/s, Epoch=21, Valid_Acc=27.3, Valid_Loss=2.77]\n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:10<00:00,  3.79it/s, Epoch=22, Train_Loss=2.71]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  8.88it/s, Epoch=22, Valid_Acc=26.7, Valid_Loss=2.67]\n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:10<00:00,  3.55it/s, Epoch=23, Train_Loss=2.67]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  8.77it/s, Epoch=23, Valid_Acc=23, Valid_Loss=2.88] \n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:09<00:00,  3.90it/s, Epoch=24, Train_Loss=2.67]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  8.99it/s, Epoch=24, Valid_Acc=25.7, Valid_Loss=3.28]\n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:09<00:00,  3.84it/s, Epoch=25, Train_Loss=2.69]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  5.93it/s, Epoch=25, Valid_Acc=31.5, Valid_Loss=2.6]\nValidation Accuracy Improved (27.67 ---> 31.5)\nModel Saved\n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:09<00:00,  3.82it/s, Epoch=26, Train_Loss=2.66]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  7.16it/s, Epoch=26, Valid_Acc=25.8, Valid_Loss=3.99]\n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:09<00:00,  3.89it/s, Epoch=27, Train_Loss=2.64]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  9.07it/s, Epoch=27, Valid_Acc=29.7, Valid_Loss=2.71]\n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:10<00:00,  3.60it/s, Epoch=28, Train_Loss=2.63]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  8.97it/s, Epoch=28, Valid_Acc=27.5, Valid_Loss=2.65]\n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:09<00:00,  3.94it/s, Epoch=29, Train_Loss=2.58]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  9.05it/s, Epoch=29, Valid_Acc=32, Valid_Loss=2.62] \nValidation Accuracy Improved (31.5 ---> 32.0)\nModel Saved\n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:09<00:00,  3.91it/s, Epoch=30, Train_Loss=2.53]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  8.52it/s, Epoch=30, Valid_Acc=27.3, Valid_Loss=2.79]\n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:10<00:00,  3.52it/s, Epoch=31, Train_Loss=2.52]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  8.79it/s, Epoch=31, Valid_Acc=31, Valid_Loss=2.64] \n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:09<00:00,  3.87it/s, Epoch=32, Train_Loss=2.5] \n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  8.90it/s, Epoch=32, Valid_Acc=30.5, Valid_Loss=2.63]\n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:10<00:00,  3.80it/s, Epoch=33, Train_Loss=2.52]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  8.44it/s, Epoch=33, Valid_Acc=32, Valid_Loss=2.66] \n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:10<00:00,  3.52it/s, Epoch=34, Train_Loss=2.43]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  8.55it/s, Epoch=34, Valid_Acc=32.3, Valid_Loss=2.6]\nValidation Accuracy Improved (32.0 ---> 32.33)\nModel Saved\n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:10<00:00,  3.78it/s, Epoch=35, Train_Loss=2.5] \n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  8.65it/s, Epoch=35, Valid_Acc=28, Valid_Loss=2.86] \n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:10<00:00,  3.73it/s, Epoch=36, Train_Loss=2.43]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  7.60it/s, Epoch=36, Valid_Acc=29.7, Valid_Loss=2.75]\n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:10<00:00,  3.49it/s, Epoch=37, Train_Loss=2.43]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  8.94it/s, Epoch=37, Valid_Acc=26.3, Valid_Loss=3.06]\n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:09<00:00,  3.83it/s, Epoch=38, Train_Loss=2.38]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  8.98it/s, Epoch=38, Valid_Acc=28.5, Valid_Loss=2.79]\n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:10<00:00,  3.46it/s, Epoch=39, Train_Loss=2.37]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  8.84it/s, Epoch=39, Valid_Acc=32.8, Valid_Loss=2.65]\nValidation Accuracy Improved (32.33 ---> 32.83)\nModel Saved\n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:10<00:00,  3.75it/s, Epoch=40, Train_Loss=2.35]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  8.74it/s, Epoch=40, Valid_Acc=30.7, Valid_Loss=2.76]\n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:10<00:00,  3.75it/s, Epoch=41, Train_Loss=2.34]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  8.34it/s, Epoch=41, Valid_Acc=34, Valid_Loss=2.58] \nValidation Accuracy Improved (32.83 ---> 34.0)\nModel Saved\n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:11<00:00,  3.41it/s, Epoch=42, Train_Loss=2.29]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  8.71it/s, Epoch=42, Valid_Acc=36.8, Valid_Loss=2.44]\nValidation Accuracy Improved (34.0 ---> 36.83)\nModel Saved\n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:10<00:00,  3.69it/s, Epoch=43, Train_Loss=2.31]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  8.57it/s, Epoch=43, Valid_Acc=32, Valid_Loss=2.74] \n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:10<00:00,  3.73it/s, Epoch=44, Train_Loss=2.24]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  8.72it/s, Epoch=44, Valid_Acc=32.3, Valid_Loss=2.78]\n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:11<00:00,  3.44it/s, Epoch=45, Train_Loss=2.25]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  8.48it/s, Epoch=45, Valid_Acc=32.2, Valid_Loss=2.8]\n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:10<00:00,  3.63it/s, Epoch=46, Train_Loss=2.23]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  8.36it/s, Epoch=46, Valid_Acc=34, Valid_Loss=2.87] \n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:11<00:00,  3.36it/s, Epoch=47, Train_Loss=2.22]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  8.62it/s, Epoch=47, Valid_Acc=31.3, Valid_Loss=2.66]\n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:10<00:00,  3.66it/s, Epoch=48, Train_Loss=2.22]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  8.39it/s, Epoch=48, Valid_Acc=33, Valid_Loss=2.74] \n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:10<00:00,  3.76it/s, Epoch=49, Train_Loss=2.26]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  8.94it/s, Epoch=49, Valid_Acc=31, Valid_Loss=2.87] \n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:11<00:00,  3.27it/s, Epoch=50, Train_Loss=2.16]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  8.70it/s, Epoch=50, Valid_Acc=34.2, Valid_Loss=2.7]\n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:10<00:00,  3.71it/s, Epoch=51, Train_Loss=2.11]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  8.28it/s, Epoch=51, Valid_Acc=33.8, Valid_Loss=2.77]\n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:10<00:00,  3.76it/s, Epoch=52, Train_Loss=2.1] \n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  8.60it/s, Epoch=52, Valid_Acc=32, Valid_Loss=2.87] \n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:11<00:00,  3.43it/s, Epoch=53, Train_Loss=2.09]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  9.03it/s, Epoch=53, Valid_Acc=33.5, Valid_Loss=2.77]\n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:10<00:00,  3.74it/s, Epoch=54, Train_Loss=2.07]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  8.80it/s, Epoch=54, Valid_Acc=33.7, Valid_Loss=3.01]\n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:10<00:00,  3.51it/s, Epoch=55, Train_Loss=2.02]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  8.45it/s, Epoch=55, Valid_Acc=30.8, Valid_Loss=2.73]\n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:10<00:00,  3.76it/s, Epoch=56, Train_Loss=2.05]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  8.51it/s, Epoch=56, Valid_Acc=31, Valid_Loss=3.09] \n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:10<00:00,  3.73it/s, Epoch=57, Train_Loss=2.01]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  8.75it/s, Epoch=57, Valid_Acc=33.3, Valid_Loss=2.73]\n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:10<00:00,  3.48it/s, Epoch=58, Train_Loss=1.98]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  8.64it/s, Epoch=58, Valid_Acc=34.8, Valid_Loss=2.74]\n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:10<00:00,  3.75it/s, Epoch=59, Train_Loss=1.96]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  7.79it/s, Epoch=59, Valid_Acc=30.8, Valid_Loss=3.03]\n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:10<00:00,  3.78it/s, Epoch=60, Train_Loss=1.91]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  8.34it/s, Epoch=60, Valid_Acc=35.5, Valid_Loss=2.83]\n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:11<00:00,  3.44it/s, Epoch=61, Train_Loss=1.9] \n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  8.12it/s, Epoch=61, Valid_Acc=33.2, Valid_Loss=3.12]\n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:10<00:00,  3.70it/s, Epoch=62, Train_Loss=1.95]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  8.46it/s, Epoch=62, Valid_Acc=33.5, Valid_Loss=2.85]\n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:10<00:00,  3.73it/s, Epoch=63, Train_Loss=1.86]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  6.96it/s, Epoch=63, Valid_Acc=32.3, Valid_Loss=3.06]\n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:10<00:00,  3.51it/s, Epoch=64, Train_Loss=1.86]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  7.54it/s, Epoch=64, Valid_Acc=32.2, Valid_Loss=2.98]\n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:10<00:00,  3.49it/s, Epoch=65, Train_Loss=1.82]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  8.51it/s, Epoch=65, Valid_Acc=35.8, Valid_Loss=2.86]\n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:11<00:00,  3.43it/s, Epoch=66, Train_Loss=1.84]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  8.35it/s, Epoch=66, Valid_Acc=31.8, Valid_Loss=3.24]\n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:10<00:00,  3.69it/s, Epoch=67, Train_Loss=1.83]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  8.16it/s, Epoch=67, Valid_Acc=35.7, Valid_Loss=2.78]\n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:10<00:00,  3.68it/s, Epoch=68, Train_Loss=1.74]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  8.75it/s, Epoch=68, Valid_Acc=33.7, Valid_Loss=2.97]\n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:11<00:00,  3.39it/s, Epoch=69, Train_Loss=1.71]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  8.26it/s, Epoch=69, Valid_Acc=35.7, Valid_Loss=2.89]\n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:10<00:00,  3.66it/s, Epoch=70, Train_Loss=1.69]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  7.75it/s, Epoch=70, Valid_Acc=34.5, Valid_Loss=3.16]\n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:10<00:00,  3.62it/s, Epoch=71, Train_Loss=1.69]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  5.49it/s, Epoch=71, Valid_Acc=35.7, Valid_Loss=3]  \n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:10<00:00,  3.66it/s, Epoch=72, Train_Loss=1.7] \n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  8.69it/s, Epoch=72, Valid_Acc=34.7, Valid_Loss=3.13]\n\n100%|\u001b[36m██████████\u001b[0m| 38/38 [00:10<00:00,  3.72it/s, Epoch=73, Train_Loss=1.68]\n100%|\u001b[36m██████████\u001b[0m| 10/10 [00:01<00:00,  8.20it/s, Epoch=73, Valid_Acc=34.8, Valid_Loss=3.16]\n\n 34%|\u001b[36m███▍      \u001b[0m| 13/38 [00:04<00:08,  3.03it/s, Epoch=74, Train_Loss=1.6] \n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[106], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# model = ResnetModel(num_classes=CONFIG['num_classes'])\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# model.to(CONFIG['device'])\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mrun_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdevice\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[104], line 10\u001b[0m, in \u001b[0;36mrun_training\u001b[0;34m(model, device, num_epochs)\u001b[0m\n\u001b[1;32m      7\u001b[0m train_loader, val_loader \u001b[38;5;241m=\u001b[39m prepare_loaders()\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m---> 10\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     12\u001b[0m         val_accuracy, val_loss \u001b[38;5;241m=\u001b[39m valid_epoch(model, val_loader, device, epoch)\n","Cell \u001b[0;32mIn[101], line 15\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, dataloader, device, epoch)\u001b[0m\n\u001b[1;32m     12\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     14\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 15\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(pred, labels)\n\u001b[1;32m     18\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","Cell \u001b[0;32mIn[98], line 13\u001b[0m, in \u001b[0;36mResnetModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 13\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackbone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/models/densenet.py:213\u001b[0m, in \u001b[0;36mDenseNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 213\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m     out \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(features, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    215\u001b[0m     out \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39madaptive_avg_pool2d(out, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/models/densenet.py:122\u001b[0m, in \u001b[0;36m_DenseBlock.forward\u001b[0;34m(self, init_features)\u001b[0m\n\u001b[1;32m    120\u001b[0m features \u001b[38;5;241m=\u001b[39m [init_features]\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 122\u001b[0m     new_features \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m     features\u001b[38;5;241m.\u001b[39mappend(new_features)\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(features, \u001b[38;5;241m1\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/models/densenet.py:88\u001b[0m, in \u001b[0;36m_DenseLayer.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     86\u001b[0m     bottleneck_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_checkpoint_bottleneck(prev_features)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 88\u001b[0m     bottleneck_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprev_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m new_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(bottleneck_output)))\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_rate \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/models/densenet.py:49\u001b[0m, in \u001b[0;36m_DenseLayer.bn_function\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbn_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs: List[Tensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m     48\u001b[0m     concated_features \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(inputs, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 49\u001b[0m     bottleneck_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu1(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconcated_features\u001b[49m\u001b[43m)\u001b[49m))  \u001b[38;5;66;03m# noqa: T484\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bottleneck_output\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:171\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    164\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2450\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m   2448\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m-> 2450\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2451\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[1;32m   2452\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"print(\"Loading best model for submission\")\nmodel.load_state_dict(torch.load(SAVE_PATH))\n\ntest_set = UnlabeledDataset(TEST_DIR, test_transforms)\n\ntest_loader = DataLoader(\n        test_set,\n        batch_size = CONFIG['val_batch_size'], \n        shuffle = False,\n        num_workers = CONFIG['num_workers'], \n        pin_memory = True\n)\n\nbuild_submission(model, test_loader, CONFIG['device'], 'submission.csv')","metadata":{"execution":{"iopub.status.busy":"2023-07-13T15:47:49.325366Z","iopub.execute_input":"2023-07-13T15:47:49.326478Z","iopub.status.idle":"2023-07-13T15:47:56.779027Z","shell.execute_reply.started":"2023-07-13T15:47:49.326417Z","shell.execute_reply":"2023-07-13T15:47:56.777768Z"},"trusted":true},"execution_count":107,"outputs":[{"name":"stdout","text":"Loading best model for submission\nSubmission saved to submission.csv\n","output_type":"stream"}]}]}